{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('png')\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"ticks\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.random as jrandom\n",
    "from jax import grad, vmap\n",
    "import jax.numpy as jnp\n",
    "\n",
    "class FourierEncoding(eqx.Module):\n",
    "    B: jax.Array\n",
    "\n",
    "    @property\n",
    "    def num_fourier_features(self) -> int:\n",
    "        return self.B.shape[0]\n",
    "\n",
    "    @property\n",
    "    def in_size(self) -> int:\n",
    "        return self.B.shape[1]\n",
    "    \n",
    "    @property\n",
    "    def out_size(self) -> int:\n",
    "        return self.B.shape[0] * 2\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_size: int, \n",
    "                 num_fourier_features: int, \n",
    "                 key: jax.random.PRNGKey, \n",
    "                 sigma: float = 1.0):\n",
    "        self.B = jax.random.normal(\n",
    "            key, shape=(num_fourier_features, in_size),\n",
    "            dtype=jax.numpy.float32) * sigma\n",
    "    \n",
    "    def __call__(self, x: jax.Array, **kwargs) -> jax.Array:\n",
    "        return jax.numpy.concatenate(\n",
    "            [jax.numpy.cos(jax.numpy.dot(self.B, x)),\n",
    "             jax.numpy.sin(jax.numpy.dot(self.B, x))],\n",
    "            axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u_1(x,y) = \\delta - \\delta(1-x) + x(1-x)N_1(x,y;\\theta),\n",
    "$$\n",
    "and,\n",
    "$$\n",
    "u_2(x,y) = x(1-x)N_2(x,y;\\theta)\n",
    "$$\n",
    "where $N_1(x,y;\\theta)$ and $N_2(x,y;\\theta)$ are neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that satisfies the boundary conditions\n",
    "u_hat_1 = lambda x, y, DELTA, model1: DELTA - DELTA * (1.0 - x) + x * (1.0 - x) * model1(jnp.array([x, y]))\n",
    "u_hat_2 = lambda x, y, model2: x * (1.0 - x) * model2(jnp.array([x, y]))\n",
    "\n",
    "u_hat_1_x = grad(u_hat_1, 0)\n",
    "u_hat_1_y = grad(u_hat_1, 1)\n",
    "\n",
    "u_hat_2_x = grad(u_hat_2, 0)\n",
    "u_hat_2_y = grad(u_hat_2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this hyperelastic material, the stored energy $E_b$ in the body can be expressed in as:\n",
    "\n",
    "$$\n",
    "E_b[\\mathbf{u}(\\cdot)] = \\int_{[0,1]^2}\\left\\{\\frac{1}{2}(\\sum_{i=1}^2\\sum_{j=1}^2{F_{ij}^2} - 2)- \\ln(\\det(\\mathbf{F})) + 50\\ln(\\det(\\mathbf{F}))^2\\right\\} dxdy,\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\mathbf{F} = \\mathbf{I} + \\nabla \\mathbf{u},\n",
    "$$\n",
    "\n",
    "where $\\mathbf{I}$ is an identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_matrix = lambda x,y,delta, model1, model2: jnp.array([[1.0 + u_hat_1_x(x, y, delta, model1), u_hat_1_y(x, y, delta, model1)], \n",
    "                                  [u_hat_2_x(x, y, model2), 1.0 + u_hat_2_y(x, y, model2)]])\n",
    "\n",
    "pde_residual = vmap(lambda x,y,delta, model1, model2: (0.5 * (jnp.square(F_matrix(x,y,delta, model1, model2)).sum() -2) \n",
    "                                                  - jnp.log(jnp.linalg.det(F_matrix(x,y,delta, model1, model2))) \n",
    "                                                  + 50 * jnp.log(jnp.linalg.det(F_matrix(x,y,delta, model1, model2))) ** 2),\n",
    "                                                  in_axes=(0,0,None, None, None))\n",
    "\n",
    "pinn_loss = lambda model, x, y, delta:jnp.mean(jnp.square(pde_residual(x,y,delta, model[0], model[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "key1, key2, key = jax.random.split(key, 3)\n",
    "num_fourier_features = 100\n",
    "width_size = 128\n",
    "depth = 4\n",
    "\n",
    "model1 = eqx.nn.Sequential([\n",
    "    eqx.nn.Lambda(\n",
    "        FourierEncoding(2, num_fourier_features, key1, sigma=6.0)),\n",
    "    eqx.nn.Lambda(\n",
    "        eqx.nn.MLP(num_fourier_features * 2, 1, width_size, depth, jnp.tanh, key=key2)),\n",
    "    eqx.nn.Lambda(\n",
    "        lambda y: y[0])])\n",
    "\n",
    "key = jax.random.PRNGKey(1)\n",
    "key1, key2, key = jax.random.split(key, 3)\n",
    "\n",
    "model2 = eqx.nn.Sequential([\n",
    "    eqx.nn.Lambda(\n",
    "        FourierEncoding(2, num_fourier_features, key1, sigma=6.0)),\n",
    "    eqx.nn.Lambda(\n",
    "        eqx.nn.MLP(num_fourier_features * 2, 1, width_size, depth, jnp.tanh, key=key2)),\n",
    "    eqx.nn.Lambda(\n",
    "        lambda y: y[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember that we need a way to filter out the parameters of the Fourier encoding\n",
    "import jax.tree_util as jtu\n",
    "filter_spec1 = jtu.tree_map(lambda _: True, model1)\n",
    "filter_spec1 = eqx.tree_at(\n",
    "    lambda tree: (tree[0].fn.B,),\n",
    "    filter_spec1,\n",
    "    replace=(False,))\n",
    "\n",
    "filter_spec2 = jtu.tree_map(lambda _: True, model2)\n",
    "filter_spec2 = eqx.tree_at(\n",
    "    lambda tree: (tree[0].fn.B,),\n",
    "    filter_spec2,\n",
    "    replace=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn(\n",
    "        loss,\n",
    "        model1,model2,\n",
    "        key,\n",
    "        optimizer,\n",
    "        filter_spec1, filter_spec2,\n",
    "        delta=0.1,\n",
    "        Lx=1.0,\n",
    "        Ly=1.0,\n",
    "        num_collocation_residual=512,\n",
    "        num_iter=10_000,\n",
    "        freq=1,\n",
    "    ):\n",
    "\n",
    "    fourier_mlp = (model1, model2)\n",
    "\n",
    "    # this is new\n",
    "    def new_loss(diff_model, static_model, x, y):\n",
    "        comb_model = eqx.combine(diff_model, static_model)\n",
    "        return loss(comb_model, x, y, delta)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def step(opt_state, model, xs, ys):\n",
    "        # added this line\n",
    "        diff_model, static_model = eqx.partition(model, (filter_spec1,filter_spec2))\n",
    "        # changed the loss to the new loss\n",
    "        value, grads = eqx.filter_value_and_grad(new_loss)(diff_model, static_model, xs, ys)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, value\n",
    "    \n",
    "    opt_state = optimizer.init(eqx.filter(fourier_mlp, eqx.is_inexact_array))\n",
    "    \n",
    "    losses = []\n",
    "    for i in range(num_iter):\n",
    "        key1, key2, key = jrandom.split(key, 3)\n",
    "        xb = jrandom.uniform(key1, (num_collocation_residual,), maxval=Lx)\n",
    "        yb = jrandom.uniform(key2, (num_collocation_residual,), maxval=Ly)\n",
    "        fourier_mlp, opt_state, value = step(opt_state, fourier_mlp, xb, yb)\n",
    "        if value == jnp.nan:\n",
    "            break\n",
    "        if i % freq == 0:\n",
    "            losses.append(value)\n",
    "            print(f\"Step {i}, residual loss {value:.3e}\")\n",
    "    return fourier_mlp, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "key, subkey = jax.random.split(key)\n",
    "optimizer = optax.adam(1e-3)\n",
    "trained_model, losses = train_pinn(\n",
    "    pinn_loss, model1, model2, key, optimizer, filter_spec1,filter_spec2,\n",
    "    num_collocation_residual=32, num_iter=2_000, freq=100, Lx=1.0, Ly=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses, '-x', label=\"MLP+Fourier\")\n",
    "# set log scale for y axis\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Iterations x 100\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "sns.despine(trim=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 1, 100)\n",
    "y = jnp.linspace(0, 1, 100)\n",
    "X, Y = jnp.meshgrid(x, y)\n",
    "\n",
    "v_u_hat_1 = vmap(u_hat_1, in_axes=(0, 0, None, None))\n",
    "u_pred_1 = v_u_hat_1(X.flatten(), Y.flatten(), 0.1, trained_model[0]).reshape(X.shape)\n",
    "\n",
    "v_u_hat_2 = vmap(u_hat_2, in_axes=(0, 0, None))\n",
    "u_pred_2 = v_u_hat_2(X.flatten(), Y.flatten(), trained_model[1]).reshape(Y.shape)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Displacement Field: u1')\n",
    "plt.contourf(x, y, u_pred_1, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Displacement Field: u2')\n",
    "plt.contourf(x, y, u_pred_2, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "Solve the problem for $\\delta=0.5$ using the same architecture as above.\n",
    "It will likely fail to train.\n",
    "If yes, then use the solution of $\\delta=0.1$ as the initial guess for $\\delta=0.2$, and then use the solution of $\\delta=0.2$ as the initial guess for $\\delta=0.3$, and so on, until you reach $\\delta=0.5$.\n",
    "This is called transfer learning.\n",
    "\n",
    "At the end, plot the final displacement field for $\\delta=0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the problem for $\\delta=0.5$ using the same architecture as above.\n",
    "key, subkey = jax.random.split(key)\n",
    "optimizer = optax.adam(1e-3)\n",
    "trained_model_B, losses_B = train_pinn(\n",
    "    pinn_loss, model1, model2, key, optimizer, filter_spec1, filter_spec2,\n",
    "    num_collocation_residual=32, num_iter=1_000, freq=100, Lx=1.0, Ly=1.0, delta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses_B, '-x', label=\"MLP+Fourier\")\n",
    "# set log scale for y axis\n",
    "ax.set_title('$\\delta = 0.5$')\n",
    "ax.set_xlabel(\"Iterations x 100\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "sns.despine(trim=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 1, 100)\n",
    "y = jnp.linspace(0, 1, 100)\n",
    "X, Y = jnp.meshgrid(x, y)\n",
    "\n",
    "v_u_hat_1 = vmap(u_hat_1, in_axes=(0, 0, None, None))\n",
    "u_pred_1 = v_u_hat_1(X.flatten(), Y.flatten(), 0.5, trained_model_B[0]).reshape(X.shape)\n",
    "\n",
    "v_u_hat_2 = vmap(u_hat_2, in_axes=(0, 0, None))\n",
    "u_pred_2 = v_u_hat_2(X.flatten(), Y.flatten(), trained_model_B[1]).reshape(Y.shape)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Displacement Field: u1')\n",
    "plt.contourf(x, y, u_pred_1, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Displacement Field: u2')\n",
    "plt.contourf(x, y, u_pred_2, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C\n",
    "\n",
    "Solve the parametric problem for $\\delta \\in [0,0.5]$. That is, build a neural network that takes $\\delta$ as input and outputs the displacement field. To do this:\n",
    "+ Modify the loss function to:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\int_0^{0.5} \\int_{[0,1]^2} \\left\\{\\frac{1}{2}(\\sum_{i}\\sum_{j}{F_{ij}^2} - 2)- \\ln(\\det(\\mathbf{F})) + 50\\ln(\\det(\\mathbf{F}))^2\\right\\} dxdy d\\delta.\n",
    "$$\n",
    "\n",
    "+ Modify the neural networks to take $\\delta$ as input, say $N_1(x,y;\\delta;\\theta)$ and $N_2(x,y;\\delta;\\theta)$. Your field will be $\\mathbf{u}(x,y;\\delta;\\theta)$.\n",
    "Use the following architecture for the neural networks:\n",
    "\n",
    "$$\n",
    "N_1(x,y;\\delta) = \\sum_{i=1}^n b_{1,i}(\\delta)t_{1,i}(x,y).\n",
    "$$\n",
    "\n",
    "Here, $n$ is your choice (start with $n=10$), $b_{1,i}$ is a neural network that takes $\\delta$ as input and outputs a scalar, and $t_{1,i}(x,y)$ is a multi-layer perceptron with 3 hidden layers, each with 128 units, and tanh activations, and Fourier features at the beginning. The same applies to $N_2(x,y;\\delta)$. This representation resembles an expansion in terms of basis functions.\n",
    "The same architecture appears in DeepONet.\n",
    "\n",
    "Plot the $x$ and $y$ displacement at $x=0.5, y=0.5$ as a function of $\\delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"ticks\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "\n",
    "class FourierEncoding(eqx.Module):\n",
    "    B: jax.Array\n",
    "\n",
    "    @property\n",
    "    def num_fourier_features(self) -> int:\n",
    "        return self.B.shape[0]\n",
    "\n",
    "    @property\n",
    "    def in_size(self) -> int:\n",
    "        return self.B.shape[1]\n",
    "    \n",
    "    @property\n",
    "    def out_size(self) -> int:\n",
    "        return self.B.shape[0] * 2\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_size: int, \n",
    "                 num_fourier_features: int, \n",
    "                 key: jax.random.PRNGKey, \n",
    "                 sigma: float = 1.0):\n",
    "        self.B = jax.random.normal(\n",
    "            key, shape=(num_fourier_features, in_size),\n",
    "            dtype=jax.numpy.float32) * sigma\n",
    "    \n",
    "    def __call__(self, x: jax.Array, **kwargs) -> jax.Array:\n",
    "        return jax.numpy.concatenate(\n",
    "            [jax.numpy.cos(jax.numpy.dot(self.B, x)),\n",
    "             jax.numpy.sin(jax.numpy.dot(self.B, x))],\n",
    "            axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from jax import grad, vmap\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "\n",
    "class ParametricModel(eqx.Module):\n",
    "    \"\"\"This model captures a simple structure made out of branches and trunks.\"\"\"\n",
    "    branch: list  # These are the b's\n",
    "    trunk: list   # These are the phi's\n",
    "\n",
    "    def __init__(self, branch_width=8, branch_depth=4, m=2, trunk_width=128, trunk_depth=4, trunk_num_fourier_features=100, key1=0, key2=1):\n",
    "        key1=jax.random.PRNGKey(key1)\n",
    "        key2=jax.random.PRNGKey(key2)\n",
    "        # self.branch = branch\n",
    "        self.branch = [eqx.nn.MLP('scalar', 'scalar', branch_width, branch_depth, jax.nn.tanh, key=k) for k in jrandom.split(key1, m)]\n",
    "        # self.trunk = trunk\n",
    "        self.trunk = [eqx.nn.Sequential([\n",
    "            FourierEncoding(2, trunk_num_fourier_features, key=k),\n",
    "            eqx.nn.MLP(trunk_num_fourier_features * 2, 'scalar', trunk_width, trunk_depth, jax.nn.tanh, key=k)]) for k in jrandom.split(key2, m)]\n",
    "        \n",
    "\n",
    "    def __call__(self, x, y, xi, **kwargs):\n",
    "        res = 0.0\n",
    "        for b, t in zip(self.branch, self.trunk):\n",
    "            res += b(xi) * t(jnp.array([x,y]))\n",
    "        return res\n",
    "\n",
    "# The model that satisfies the boundary conditions\n",
    "u_hat_1 = lambda x, y, DELTA, model1: DELTA - DELTA * (1.0 - x) + x * (1.0 - x) * model1(x, y, DELTA)\n",
    "u_hat_2 = lambda x, y, DELTA, model2: x * (1.0 - x) * model2(x, y, DELTA)\n",
    "\n",
    "u_hat_1_x = grad(u_hat_1, 0)\n",
    "u_hat_1_y = grad(u_hat_1, 1)\n",
    "\n",
    "u_hat_2_x = grad(u_hat_2, 0)\n",
    "u_hat_2_y = grad(u_hat_2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4\n",
    "model1 = ParametricModel(key1=1234, key2=5678, m=M)\n",
    "model2 = ParametricModel(key1=3241, key2=3465, m=M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember that we need a way to filter out the parameters of the Fourier encoding\n",
    "import jax.tree_util as jtu\n",
    "filter_spec1 = jtu.tree_map(lambda _: True, model1)\n",
    "for l in range(M):\n",
    "# print(filter_spec1.trunk[0].layers[0].B)\n",
    "    filter_spec1 = eqx.tree_at(\n",
    "        lambda tree: (tree.trunk[l].layers[0].B,),\n",
    "        filter_spec1,\n",
    "        replace=(False,))\n",
    "\n",
    "filter_spec2 = jtu.tree_map(lambda _: True, model2)\n",
    "for l in range(M):\n",
    "    filter_spec2 = eqx.tree_at(\n",
    "        lambda tree: (tree.trunk[l].layers[0].B,),\n",
    "        filter_spec2,\n",
    "        replace=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_matrix = lambda x,y,delta, model1, model2: jnp.array([[1.0 + u_hat_1_x(x, y, delta, model1), u_hat_1_y(x, y, delta, model1)], \n",
    "                                  [u_hat_2_x(x, y, delta, model2), 1.0 + u_hat_2_y(x, y, delta, model2)]])\n",
    "\n",
    "pde_residual = vmap(lambda x,y,delta, model1, model2: (0.5 * (jnp.square(F_matrix(x,y,delta, model1, model2)).sum() -2) \n",
    "                                                  - jnp.log(jnp.linalg.det(F_matrix(x,y,delta, model1, model2))) \n",
    "                                                  + 50 * jnp.log(jnp.linalg.det(F_matrix(x,y,delta, model1, model2))) ** 2),\n",
    "                                                  in_axes=(0,0,0, None, None))\n",
    "\n",
    "pinn_loss = lambda model, x, y, delta:jnp.mean(jnp.square(pde_residual(x,y,delta, model[0], model[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn(\n",
    "        loss,\n",
    "        model1,model2,\n",
    "        key,\n",
    "        optimizer,\n",
    "        filter_spec1, filter_spec2,\n",
    "        Lx=1.0,\n",
    "        Ly=1.0,\n",
    "        num_collocation_residual=512,\n",
    "        num_xis = 16,\n",
    "        num_iter=10_000,\n",
    "        freq=1,\n",
    "    ):\n",
    "\n",
    "    fourier_mlp = (model1, model2)\n",
    "\n",
    "    # this is new\n",
    "    def new_loss(diff_model, static_model, x, y, xis):\n",
    "        comb_model = eqx.combine(diff_model, static_model)\n",
    "        return loss(comb_model, x, y, xis)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def step(opt_state, model, xs, ys, xis):\n",
    "        # added this line\n",
    "        diff_model, static_model = eqx.partition(model, (filter_spec1,filter_spec2))\n",
    "        # changed the loss to the new loss\n",
    "        value, grads = eqx.filter_value_and_grad(new_loss)(diff_model, static_model, xs, ys, xis)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, value\n",
    "    \n",
    "    opt_state = optimizer.init(eqx.filter(fourier_mlp, eqx.is_inexact_array))\n",
    "    \n",
    "    losses = []\n",
    "    for i in range(num_iter):\n",
    "        key1, key2, key3, key = jrandom.split(key, 4)\n",
    "        xb = jrandom.uniform(key1, (num_collocation_residual,), maxval=Lx)\n",
    "        yb = jrandom.uniform(key2, (num_collocation_residual,), maxval=Ly)\n",
    "        xis = jrandom.uniform(key3, (num_xis,))\n",
    "        fourier_mlp, opt_state, value = step(opt_state, fourier_mlp, xb, yb, xis)\n",
    "        if value == jnp.nan:\n",
    "            break\n",
    "        if i % freq == 0:\n",
    "            losses.append(value)\n",
    "            print(f\"Step {i}, residual loss {value:.3e}\")\n",
    "    return fourier_mlp, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, residual loss 1.217e+02\n",
      "Step 100, residual loss 2.741e+00\n",
      "Step 200, residual loss 7.437e-01\n",
      "Step 300, residual loss 7.720e-01\n",
      "Step 400, residual loss 1.373e+00\n",
      "Step 500, residual loss 7.494e-01\n",
      "Step 600, residual loss 6.145e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _xla_gc_callback at 0x132af9800>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rohan/anaconda3/lib/python3.11/site-packages/jax/_src/lib/__init__.py\", line 98, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700, residual loss 8.213e-01\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "optimizer = optax.adam(1e-3)\n",
    "trained_model, losses = train_pinn(\n",
    "    pinn_loss, model1, model2, key, optimizer, filter_spec1,filter_spec2,\n",
    "    num_collocation_residual=32, num_iter=2_000, freq=100, Lx=1.0, Ly=1.0, num_xis=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses, '-o', label=\"MLP+Fourier\")\n",
    "# set log scale for y axis\n",
    "ax.set_xlabel(\"Iterations x 100\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "sns.despine(trim=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.5\n",
    "y = 0.5\n",
    "delta = np.linspace(0,0.5,100)\n",
    "\n",
    "# u_hat_1 = lambda x, y, DELTA, model1: DELTA - DELTA * (1.0 - x) + x * (1.0 - x) * model1(x, y, DELTA)\n",
    "# u_hat_2 = lambda x, y, DELTA, model2: x * (1.0 - x) * model2(x, y, DELTA)\n",
    "\n",
    "v_u_hat_1 = vmap(u_hat_1, in_axes=(None, None, 0, None))\n",
    "u_pred_1 = v_u_hat_1(x, y, delta, trained_model[0])\n",
    "\n",
    "v_u_hat_2 = vmap(u_hat_2, in_axes=(None, None, 0, None))\n",
    "u_pred_2 = v_u_hat_2(x, y, delta, trained_model[1])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Displacement Field: u1')\n",
    "plt.plot(delta, u_pred_1)\n",
    "plt.xlabel('$\\delta$')\n",
    "# plt.ylabel('y')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Displacement Field: u2')\n",
    "plt.plot(delta, u_pred_2)\n",
    "plt.xlabel('$\\delta$')\n",
    "# plt.ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
